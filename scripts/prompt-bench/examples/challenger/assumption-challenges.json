[
  {
    "id": "challenge-071",
    "description": "Assuming immediate user adoption \u2014 should challenge assumption",
    "decision": "Feature Launch Plan for Real-Time Collaboration: We're launching real-time collaborative editing (Google Docs-style) in Sprint 20. Post-launch, we'll immediately deprecate the current single-user editing mode since everyone will prefer the collaborative version. We're allocating zero engineering time for maintaining the old editor after launch. The marketing team is preparing a blog post announcing the transition. All existing documents will be migrated to the collaborative format automatically.",
    "context": "Current editor has been used by 8,000 users for 2 years. No user research or beta testing has been done for the collaborative feature. A user survey 6 months ago showed 45% of users work alone and 55% collaborate. The collaborative editor has a different UI with a steeper learning curve. No A/B testing or gradual rollout is planned.",
    "expected": {
      "passed": true,
      "mustContain": [
        "assum"
      ],
      "mustNotContain": []
    }
  },
  {
    "id": "challenge-072",
    "description": "Assuming API can handle 10x traffic \u2014 should challenge assumption",
    "decision": "Black Friday Preparation: We're running a major promotion expecting 10x normal traffic for 48 hours. Our preparation plan: increase auto-scaling max from 6 to 12 instances. That should handle 10x traffic since each instance handles about 1,000 requests/second and our normal traffic is 6,000 req/s. No other changes needed \u2014 our code is already optimized. We'll monitor Datadog dashboards during the event and scale up further if needed.",
    "context": "Current peak traffic: 6,000 req/s spread evenly across 6 instances. Load testing was last done 8 months ago with up to 3x traffic. Database connection pool is 200 connections (shared across all instances). Redis cache is on a single node with 6GB memory. CDN is configured for static assets only \u2014 API calls go directly to the application. The team's last experience with high-traffic events was 2x normal, during which the database became the bottleneck at 3x traffic in staging.",
    "expected": {
      "passed": true,
      "mustContain": [
        "assum"
      ],
      "mustNotContain": []
    }
  },
  {
    "id": "challenge-073",
    "description": "Assuming refactor won't break anything \u2014 should challenge assumption",
    "decision": "Refactoring Plan: We're extracting the authentication middleware into a shared package used by all 5 microservices. Since all services use the same auth logic (copied from the original monolith), this is a pure deduplication \u2014 no behavior changes. We'll publish the package to our private npm registry and update all 5 services to import from there instead of using their local copies. We can do this in a single PR per service since nothing is changing functionally. No additional testing needed beyond existing tests passing.",
    "context": "The auth logic was copied to each service 18 months ago. Since then, each service has made small modifications: Service A added rate limiting, Service B added IP allowlisting, Service C handles a custom OAuth provider, Services D and E added different token expiration logic. These divergences are documented in service READMEs but not in a central location. Total auth-related tests across all services: 67.",
    "expected": {
      "passed": true,
      "mustContain": [
        "assum"
      ],
      "mustNotContain": []
    }
  },
  {
    "id": "challenge-074",
    "description": "Assuming one sprint is enough for complex migration \u2014 should challenge assumption",
    "decision": "Migration Plan: We'll migrate from MongoDB to PostgreSQL in a single sprint (2 weeks). Plan: Week 1 \u2014 set up PostgreSQL schema, write migration scripts for all 12 collections, migrate the data. Week 2 \u2014 update all 30 endpoints to use Prisma instead of Mongoose, update tests, deploy. We have a clear mapping of MongoDB documents to PostgreSQL tables. The data model is straightforward \u2014 no deeply nested documents or polymorphic schemas. Total data: 2GB across 12 collections.",
    "context": "Team of 3 engineers, none have done a database migration before. Current application has 30 endpoints, 120 database queries using Mongoose, and 200 tests. MongoDB has been in use for 3 years. Some queries use MongoDB-specific features (aggregation pipelines, $lookup, text search). The application serves production traffic 24/7 with no scheduled maintenance windows. Velocity average: 20 points per sprint.",
    "expected": {
      "passed": true,
      "mustContain": [
        "assum"
      ],
      "mustNotContain": []
    }
  },
  {
    "id": "challenge-075",
    "description": "Assuming third-party API is reliable \u2014 should challenge assumption",
    "decision": "Integration Architecture: Our checkout flow will call the shipping rate API synchronously during checkout. When a user clicks 'Calculate Shipping,' we make a real-time API call to ShipFast (our shipping provider) and display the result. No caching of shipping rates since they change based on real-time carrier availability. If ShipFast is slow, we'll show a loading spinner. Our checkout conversion rate depends on fast, accurate shipping quotes. ShipFast guarantees 200ms response times in their API docs.",
    "context": "ShipFast is a startup with 50 employees, launched 18 months ago. Their API status page shows 99.5% uptime over the last 90 days (about 10.8 hours of downtime). Response times have spiked above 2 seconds during three separate incidents. Our checkout flow processes 500 orders/hour during peak. No fallback shipping rate calculation exists. The contract with ShipFast has no SLA for API availability.",
    "expected": {
      "passed": true,
      "mustContain": [
        "assum"
      ],
      "mustNotContain": []
    }
  },
  {
    "id": "challenge-076",
    "description": "Assuming team can learn new technology during sprint \u2014 should challenge assumption",
    "decision": "Sprint 22 Plan: We'll implement the real-time notifications feature using WebSockets with Socket.IO, a Redis pub/sub layer for cross-instance messaging, and React Query for client-side state management. None of these technologies are currently in our stack. The team will learn them during implementation \u2014 there are plenty of tutorials and the technologies are well-documented. Sprint estimate: 20 story points across 5 issues. We're confident because the individual concepts aren't that complex.",
    "context": "Team of 4 engineers with 2-3 years experience each. Current stack: REST APIs, PostgreSQL, React with useState/useEffect. No team member has built a WebSocket application, used Redis pub/sub, or used React Query. Sprint velocity: 19-21 points. Last time the team introduced a new technology (GraphQL in Sprint 15), the sprint delivered only 12 of 20 planned points due to learning curve.",
    "expected": {
      "passed": true,
      "mustContain": [
        "assum"
      ],
      "mustNotContain": []
    }
  },
  {
    "id": "challenge-077",
    "description": "Assuming microservices will be simpler \u2014 should challenge assumption",
    "decision": "Architecture Proposal: Split our monolith into 8 microservices (User, Auth, Payment, Order, Notification, Search, Analytics, Admin). Each service will have its own database, API, and deployment pipeline. This will make the codebase easier to understand since each service is smaller. It will also allow us to scale individual services independently and deploy them separately. We'll start the split next sprint and aim to complete it in 3 months. The team will learn Kubernetes to orchestrate the services.",
    "context": "Current monolith: 15,000 lines of TypeScript, 4 engineers, 200 tests, single PostgreSQL database. The monolith handles 2,000 req/min with 99.9% uptime. No team member has experience with microservices, Kubernetes, or distributed systems. The monolith has been in production for 2 years. Deployment takes 5 minutes via a single CI/CD pipeline. No current performance or scaling issues.",
    "expected": {
      "passed": true,
      "mustContain": [
        "assum"
      ],
      "mustNotContain": []
    }
  },
  {
    "id": "challenge-078",
    "description": "Assuming users don't need offline capability \u2014 should challenge assumption",
    "decision": "Mobile App Architecture: The app will require a constant internet connection for all functionality. Every action (viewing data, editing, saving) makes a server round-trip. No local data caching or offline mode. Our users are office workers who always have WiFi, so offline capability is unnecessary engineering effort. If the connection drops, we'll show a 'No Internet' error screen and the user can retry when they're back online.",
    "context": "Target users: field sales representatives who visit client offices, attend trade shows, and travel frequently. User research from 3 months ago showed 30% of users reported 'inconsistent internet' as a pain point with the current web app. Competitor apps (Salesforce, HubSpot mobile) all offer offline mode. The app will be used in 15 countries including regions with spotty mobile coverage.",
    "expected": {
      "passed": true,
      "mustContain": [
        "assum"
      ],
      "mustNotContain": []
    }
  },
  {
    "id": "challenge-079",
    "description": "Assuming current testing is sufficient for compliance \u2014 should challenge assumption",
    "decision": "Compliance Readiness Assessment: We're pursuing SOC 2 Type II certification. Our engineering team believes we're already compliant because we have automated tests, code reviews, and CI/CD pipelines. We'll submit our current processes for audit without changes. Our test coverage is 82%, all PRs require one approval, and deployments go through staging before production. We've never had a security breach, which proves our practices are sound.",
    "context": "SOC 2 Type II requires: access control policies, audit logging, incident response procedures, vendor management, data retention policies, employee onboarding/offboarding procedures, change management documentation, risk assessments, and business continuity plans. Current state: no formal access control policy document, no centralized audit logging, no documented incident response procedure, no vendor assessment records, no data retention policy, and no business continuity plan. Engineering practices are good but undocumented.",
    "expected": {
      "passed": true,
      "mustContain": [
        "assum"
      ],
      "mustNotContain": []
    }
  },
  {
    "id": "challenge-080",
    "description": "Assuming linear performance scaling \u2014 should challenge assumption",
    "decision": "Scaling Plan: Our current API server handles 1,000 concurrent users on a single instance. For our product launch expecting 10,000 concurrent users, we'll simply run 10 instances behind a load balancer. Linear scaling \u2014 10x instances for 10x users. No code changes needed. We'll pre-provision the instances a day before launch and scale back after the initial surge. Budget is approved for 10 instances for 1 month.",
    "context": "Application uses a shared PostgreSQL database with a connection pool of 50 per instance. That means 10 instances = 500 connections, but the database max_connections is 200. The application uses server-side sessions stored in memory (not Redis). WebSocket connections are used for real-time features and are not sticky-session aware on the load balancer. Cache invalidation uses process-local events. Database queries include several N+1 patterns that become worse with concurrent users.",
    "expected": {
      "passed": true,
      "mustContain": [
        "assum"
      ],
      "mustNotContain": []
    }
  },
  {
    "id": "challenge-081",
    "description": "Assuming no data model changes needed \u2014 should challenge assumption",
    "decision": "Multi-tenancy Plan: We're adding multi-tenant support to our single-tenant SaaS application. Plan: add a 'tenant_id' column to the users table and filter all queries by tenant_id. This is a 'simple' change \u2014 just add the column and update the WHERE clauses. We've identified 8 queries that need the tenant_id filter. Estimated effort: 5 story points. We don't need to change the data model beyond adding the tenant_id column since our schema is already normalized.",
    "context": "Application has 30 tables with complex relationships. Reports aggregate data across users (e.g., 'total revenue' would show all tenants' revenue without proper scoping). File uploads are stored in a single S3 bucket with user-ID-based paths (no tenant isolation). Background jobs process all users in a single queue. API rate limits are global, not per-tenant. The search index is shared. Audit logs don't include tenant context. Email templates reference global settings.",
    "expected": {
      "passed": true,
      "mustContain": [
        "assum"
      ],
      "mustNotContain": []
    }
  },
  {
    "id": "challenge-082",
    "description": "Assuming competitor comparison applies to own product \u2014 should challenge assumption",
    "decision": "Pricing Strategy Change: We're tripling our prices effective next month based on competitive analysis. Our closest competitor charges 3x what we charge for similar features. Their churn rate is only 5% monthly, proving that customers are willing to pay premium prices. We'll send a 2-week notice to existing customers and grandfather no one \u2014 all accounts switch to the new pricing on the same date. Expected revenue impact: 3x increase with minimal churn.",
    "context": "Current customer base: 500 companies, average contract value $200/month. Competitor has brand recognition, 10x more features, enterprise support, and has been in market for 8 years. Our product launched 14 months ago. Customer satisfaction surveys show price is the #1 reason customers choose us over competitors. 60% of customers are on month-to-month contracts with no lock-in. We have no enterprise support team.",
    "expected": {
      "passed": true,
      "mustContain": [
        "assum"
      ],
      "mustNotContain": []
    }
  },
  {
    "id": "challenge-083",
    "description": "Assuming AI-generated code doesn't need review \u2014 should challenge assumption",
    "decision": "Development Process Update: Since we've adopted AI coding assistants (GitHub Copilot), we're reducing our code review requirements. AI-generated code is high quality and follows best practices, so PRs where >80% of the code was AI-generated only need a quick scan instead of a full review. This will cut our review time in half. The AI assistant already checks for security issues, follows our coding standards, and writes tests. Reviewers should focus on PRs with mostly human-written code.",
    "context": "Last quarter, 3 bugs made it to production that were in AI-generated code: a SQL injection vulnerability (AI used string interpolation instead of parameterized queries), an infinite loop in a retry mechanism (AI didn't add a max retry count), and incorrect date timezone handling (AI assumed UTC everywhere). All three passed quick-scan reviews. The team has been using AI assistants for 4 months.",
    "expected": {
      "passed": true,
      "mustContain": [
        "assum"
      ],
      "mustNotContain": []
    }
  },
  {
    "id": "challenge-084",
    "description": "Assuming backward compatibility without verification \u2014 should challenge assumption",
    "decision": "Library Upgrade Plan: Upgrade our shared UI component library from v3 to v5 (skipping v4). The v5 changelog says 'mostly backward compatible with v3.' We'll do a global find-and-replace for the 4 renamed components mentioned in the changelog, update the import paths, and deploy. No need for a comprehensive audit of breaking changes \u2014 the changelog covers everything important. Estimated effort: 2 story points for the find-and-replace and testing.",
    "context": "The UI component library is used in 85 React components across the application. The v4 changelog (which we're skipping) listed 12 breaking changes and 3 deprecated APIs. The v5 changelog mentions 4 renamed components but says 'see v4 changelog for previous breaking changes.' The application has no visual regression testing. Component tests cover functionality but not visual appearance. Last library upgrade (v2 to v3) took 3 sprints due to unexpected breaking changes in CSS specificity.",
    "expected": {
      "passed": true,
      "mustContain": [
        "assum"
      ],
      "mustNotContain": []
    }
  },
  {
    "id": "challenge-085",
    "description": "Assuming build-vs-buy favors building without analysis \u2014 should challenge assumption",
    "decision": "Build Decision: Instead of using Auth0 or Clerk for authentication, we'll build our own auth system. We need full control over the login experience and user data. We'll implement: email/password authentication, OAuth (Google, GitHub, Microsoft), magic links, MFA with TOTP and SMS, session management, password reset flows, account lockout after failed attempts, CSRF protection, and JWT token management. Two engineers can build this in 3 sprints. Building our own gives us flexibility to add custom features later.",
    "context": "Team of 5 engineers total (2 assigned to auth). No team member has built a production auth system before. Auth0 costs $240/month for our projected user count. The product roadmap has 8 critical features waiting in the backlog. Last time the team built a 'simple' feature from scratch (file upload system), it took 3x the estimate and had 2 security vulnerabilities discovered post-launch. The product targets enterprise customers who will ask about security certifications.",
    "expected": {
      "passed": true,
      "mustContain": [
        "assum"
      ],
      "mustNotContain": []
    }
  }
]
